{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = '/scratch/yk1962/ABC/result/chamfer_distance_result/sub_results'\n",
    "result_matrix_path = '/scratch/yk1962/ABC/result/chamfer_distance_result/chamfer_distance_sparse.npz'\n",
    "data_dir = '/scratch/yk1962/ABC/data/pc_correct_num_40960'\n",
    "check_integrity = False\n",
    "check_excessive_result = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Check Data Integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = sorted(os.listdir(result_dir), key=lambda name: int(name.split('_')[-2]))\n",
    "data_list = os.listdir(data_dir)\n",
    "start_end = {}\n",
    "for full_name in result_list:\n",
    "    split = full_name.split('_')\n",
    "    try:\n",
    "        start = int(split[-2])\n",
    "        end = int(split[-1].split('.')[0])\n",
    "    except:\n",
    "        print(full_name)\n",
    "        break\n",
    "    if start in start_end:\n",
    "        print(\"duplicated results! for start\", start, \"already have end\", start_end[start], \"but now also have\", end)\n",
    "        raise Exception(\"fix this before moving on!\")\n",
    "    start_end[start] = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if check_integrity:\n",
    "    def find_next_in_dict(start_end, start):\n",
    "        keys = np.array(list(start_end.keys()))\n",
    "        after_start = keys[keys > start]\n",
    "        return min(after_start)\n",
    "\n",
    "    current_start = 0\n",
    "    num_res = len(result_list)\n",
    "    error_list = [\"\"]\n",
    "    print_step = 50\n",
    "    for result_count in range(num_res):\n",
    "        try:\n",
    "            current_end = start_end[current_start]\n",
    "        except:\n",
    "            try:\n",
    "                current_end = find_next_in_dict(start_end, current_start)\n",
    "            except:\n",
    "                current_end = current_start\n",
    "                break\n",
    "            full_name = \"chamfer_distance_{}_{}.csv\".format(current_start, current_end)\n",
    "            print(\"missing the result\", full_name)\n",
    "            if error_list[-1] != full_name: error_list.append(full_name)\n",
    "            current_start = current_end\n",
    "            if result_count % print_step == 0:\n",
    "                print(\"result\", result_count, \"finished.\")\n",
    "            continue\n",
    "        full_name = \"chamfer_distance_{}_{}.csv\".format(current_start, current_end)\n",
    "        row_count = 0\n",
    "        with open(os.path.join(result_dir, full_name), 'r', newline='') as current_result:\n",
    "            for row_idx, row in enumerate(csv.reader(current_result)):\n",
    "                try:\n",
    "                    assert(len(row) == current_start + row_idx + 1)\n",
    "                except:\n",
    "                    print(\"number of columns in row\", row_idx, \"of file\", full_name, \"should be\", current_start + row_idx + 1, \\\n",
    "                         \"but get\", len(row), \"instead.\")\n",
    "                    if error_list[-1] != full_name: error_list.append(full_name) \n",
    "                row_count += 1\n",
    "        try:\n",
    "            assert(row_count == current_end - current_start)\n",
    "        except:\n",
    "            print(\"number of rows of file\", full_name, \"should be\", current_end - current_start, \\\n",
    "                  \"but get\", row_count, \"instead.\")\n",
    "            if error_list[-1] != full_name: error_list.append(full_name)\n",
    "        current_start = current_end\n",
    "        if result_count % print_step == 0:\n",
    "            print(\"result\", result_count, \"finished.\")\n",
    "\n",
    "    error_list = error_list[1:]\n",
    "    try:\n",
    "        assert(current_end == len(data_list))\n",
    "    except:\n",
    "        print(\"expecting\", len(data_list), \"objects but get\", current_end, \"objects\")\n",
    "        full_name = \"chamfer_distance_{}_{}.csv\".format(current_end, len(data_list))\n",
    "        error_list.append(full_name) \n",
    "    print(\"number of results:\", num_res)\n",
    "    print(\"numer of errors:\", len(error_list))\n",
    "    if len(error_list) > 0:\n",
    "        print(\"error list:\")\n",
    "        print(error_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recalculate(jstart, \n",
    "                jend, \n",
    "                run_time=\"11:59:59\", \n",
    "                gpu_type=\"rtx8000\", \n",
    "                sbatch_dir=\"job_request\", \n",
    "                split=False, \n",
    "                split_num=4,\n",
    "                project_dir=\"/scratch/yk1962/ABC\",\n",
    "                data_dir=\"data/pc_correct_num_40960\",\n",
    "                result_dir=\"result\",\n",
    "                output_dir=\"output\",\n",
    "                netid=\"yk1962\",\n",
    "                activate_path=\"/scratch/yk1962/miniconda3/bin/activate\",\n",
    "                path_to_code=\"code\",\n",
    "                main_project_dir=\"/scratch/yk1962/ABC\",\n",
    "               ):\n",
    "    content = \\\n",
    "    \"#!/bin/bash -e\\n\" \\\n",
    "    \"#\\n\" \\\n",
    "    \"#SBATCH --nodes=1\\n\" \\\n",
    "    \"#SBATCH --ntasks-per-node=1\\n\" \\\n",
    "    \"#SBATCH --cpus-per-task=2\\n\" \\\n",
    "    \"#SBATCH --time={}\\n\" \\\n",
    "    \"#SBATCH --mem=10GB\\n\" \\\n",
    "    \"#SBATCH --job-name=chamfer_distance_{}-{} \\n\" \\\n",
    "    \"#SBATCH --mail-user={}@nyu.edu \\n\" \\\n",
    "    \"#SBATCH --output={}/{}/slurm_%j_{}_{}.out\\n\" \\\n",
    "    \"#SBATCH --gres=gpu:{}:1\\n\" \\\n",
    "    \"\\n\" \\\n",
    "    \"module purge\\n\" \\\n",
    "    \"\\n\" \\\n",
    "    \"# Enter required modules\\n\" \\\n",
    "    \"\\n\" \\\n",
    "    \"# Execute Commands\\n\" \\\n",
    "    \"cd {}/{}\\n\" \\\n",
    "    \"source {} pytorch3d\\n\" \\\n",
    "    \"python chamfer_distance.py {} {} {} -start={} -end={} -cuda_name=cuda:0\\n\"\n",
    "        \n",
    "    if not split:\n",
    "        current_content = content.format(run_time,\n",
    "                                 jstart, jend,\n",
    "                                 netid,\n",
    "                                 project_dir, output_dir, jstart, jend,\n",
    "                                 gpu_type,\n",
    "                                 project_dir, path_to_code,\n",
    "                                 activate_path,\n",
    "                                 project_dir, data_dir, result_dir, jstart, jend)\n",
    "        job_path = os.path.join(project_dir, sbatch_dir, \"job_{}-{}.sh\".format(jstart, jend))\n",
    "        with open(job_path, \"w\") as f:\n",
    "            f.write(current_content)\n",
    "    else:\n",
    "        split_num = min(split_num, jend-jstart-1)\n",
    "        split_range = np.linspace(jstart, jend, split_num+1, dtype=int)\n",
    "        split_range[-1] = jend\n",
    "        for i in range(split_num):\n",
    "            sub_jstart = split_range[i]\n",
    "            sub_jend = split_range[i+1]\n",
    "            assert(sub_jend > sub_jstart)\n",
    "            current_content = content.format(run_time,\n",
    "                                 sub_jstart, sub_jend,\n",
    "                                 netid,\n",
    "                                 project_dir, output_dir, sub_jstart, sub_jend,\n",
    "                                 gpu_type,\n",
    "                                 project_dir, path_to_code,\n",
    "                                 activate_path,\n",
    "                                 project_dir, data_dir, result_dir, sub_jstart, sub_jend)\n",
    "            job_path = os.path.join(main_project_dir, sbatch_dir, \"job_{}_{}-{}.sh\".format(netid, sub_jstart, sub_jend))\n",
    "            with open(job_path, \"w\") as f:\n",
    "                f.write(current_content)\n",
    "#     os.system(\"sbatch {}\".format(job_path))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_integrity:\n",
    "    if len(error_list) != 0:\n",
    "        split = False\n",
    "        split_num = 12\n",
    "        for idx, error_csv in enumerate(error_list):\n",
    "            os.system(\"mv {} ~/trash\".format(os.path.join(result_dir, error_csv)))\n",
    "            result_split = error_csv.split('_')\n",
    "            start = int(result_split[-2])\n",
    "            end = int(result_split[-1].split('.')[0])\n",
    "            if (not split) or idx < len(error_list) // 2:\n",
    "                recalculate(start, \n",
    "                            end, \n",
    "                            run_time=\"11:59:58\", \n",
    "                            gpu_type=\"rtx8000\", \n",
    "                            sbatch_dir=\"job_request\", \n",
    "                            split=split, \n",
    "                            split_num=split_num,\n",
    "                            project_dir=\"/scratch/yk1962/ABC\",\n",
    "                            data_dir=\"data/pc_correct_num_40960\",\n",
    "                            result_dir=\"result\",\n",
    "                            output_dir=\"output\",\n",
    "                            netid=\"yk1962\",\n",
    "                            activate_path=\"/scratch/yk1962/miniconda3/bin/activate\",\n",
    "                            path_to_code=\"code\",\n",
    "                            main_project_dir=\"/scratch/yk1962/ABC\",\n",
    "                           )\n",
    "            else:\n",
    "                recalculate(start, \n",
    "                            end, \n",
    "                            run_time=\"11:59:58\", \n",
    "                            gpu_type=\"rtx8000\", \n",
    "                            sbatch_dir=\"job_request\", \n",
    "                            split=split, \n",
    "                            split_num=split_num,\n",
    "                            project_dir=\"/scratch/sx783/ABC2\",\n",
    "                            data_dir=\"data/pc_correct_num_40960\",\n",
    "                            result_dir=\"result\",\n",
    "                            output_dir=\"output\",\n",
    "                            netid=\"sx783\",\n",
    "                            activate_path=\"/scratch/sx783/miniconda3/bin/activate\",\n",
    "                            path_to_code=\"code\",\n",
    "                            main_project_dir=\"/scratch/yk1962/ABC\",\n",
    "                           )\n",
    "            print(\"generated job from\", start, \"to {}.\".format(end))\n",
    "        print(\"job generated. go to shell to submit the jobs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_excessive_result:\n",
    "    starts = []\n",
    "    current_start = 0\n",
    "    while current_start in start_end:\n",
    "        starts.append(current_start)\n",
    "        current_start = start_end[current_start]\n",
    "    if len(starts) != len(result_list):\n",
    "        assert(len(starts) < len(result_list))\n",
    "        print(\"exist\", len(result_list)-len(starts), \"extra files\")\n",
    "        excessive_result = []\n",
    "        for result_name in result_list:\n",
    "            if int(result_name.split('_')[-2]) not in starts:\n",
    "                excessive_result.append(result_name)\n",
    "                os.system(\"mv {} ~/trash\".format(os.path.join(result_dir, result_name)))\n",
    "        print(\"removed excessive results:\", excessive_result)\n",
    "        raise Exception(\"fix this before moving on!\")\n",
    "    else:\n",
    "        print(\"no excessive result.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MergeResults(object):\n",
    "    def __init__(self, data_list, result_list, result_dir):\n",
    "        # check result_list\n",
    "        previous_end = result_list[0].split('_')[-1].split('.')[0]\n",
    "        for i in range(1, len(result_list)):\n",
    "            split = result_list[i].split('_')\n",
    "            start = split[-2]\n",
    "            try: \n",
    "                assert(start == previous_end)\n",
    "            except:\n",
    "                raise Exception(result_list[i-1], result_list[i])\n",
    "            previous_end = split[-1].split('.')[0]\n",
    "        self.result_list = result_list\n",
    "        self.result_dir = result_dir\n",
    "        \n",
    "        self.data_list = np.asarray(data_list)\n",
    "        self.n = len(data_list)\n",
    "        self.unsortedidx_sortedidx = np.zeros(self.n, dtype=int)\n",
    "        for sortedidx, unsortedidx in enumerate(np.argsort(self.data_list)):\n",
    "            self.unsortedidx_sortedidx[unsortedidx] = sortedidx\n",
    "        \n",
    "        self.data = np.zeros(self.n * (self.n-1) // 2)\n",
    "        self.ii = np.zeros(self.n * (self.n-1) // 2, dtype=int)\n",
    "        self.jj = np.zeros(self.n * (self.n-1) // 2, dtype=int)\n",
    "#         self.data = [0.] * (self.n * (self.n-1) // 2) \n",
    "#         self.ii = [0] * (self.n * (self.n-1) // 2) \n",
    "#         self.jj = [0] * (self.n * (self.n-1) // 2) \n",
    "        self.dist_count = 0\n",
    "        self.row_count = 0\n",
    "        self.sorted_data_list = sorted(data_list)\n",
    "        \n",
    "            \n",
    "    def add_distance(self, idx1, idx2, distance):\n",
    "        assert(idx1 != idx2)\n",
    "        self.data[self.dist_count] = distance\n",
    "        if idx1 < idx2:\n",
    "            self.ii[self.dist_count] = idx2\n",
    "            self.jj[self.dist_count] = idx1\n",
    "        else:\n",
    "            self.ii[self.dist_count] = idx1\n",
    "            self.jj[self.dist_count] = idx2\n",
    "        self.dist_count += 1\n",
    "        \n",
    "    def merge_results(self):\n",
    "        for result_name in tqdm(self.result_list):\n",
    "            with open(os.path.join(self.result_dir, result_name), 'r', newline='') as result:\n",
    "                for row_idx, row in enumerate(csv.reader(result)):\n",
    "                    distance_enum = enumerate(row, start=-1)\n",
    "                    row_name = distance_enum.__next__()[1]\n",
    "                    sorted_row_idx = self.unsortedidx_sortedidx[self.row_count]\n",
    "                    try: \n",
    "                        assert(row_name == self.sorted_data_list[sorted_row_idx])\n",
    "                    except:\n",
    "                        raise Exception(\"in\" + result_name + \"row\" + row_idx + \"row name should be\" + row_name +\\\n",
    "                                        \"but get\" + self.sorted_data_list[sorted_row_idx])\n",
    "                        \n",
    "                    for column_idx, distance in distance_enum:\n",
    "                        sorted_column_idx = self.unsortedidx_sortedidx[column_idx]\n",
    "                        self.add_distance(sorted_column_idx, sorted_row_idx, distance)\n",
    "                    self.row_count += 1\n",
    "                self.row_start = row_idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 44944 is out of bounds for axis 0 with size 22968",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-679ed2866dbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmerger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMergeResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmerger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsortedidx_sortedidx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m44944\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 44944 is out of bounds for axis 0 with size 22968"
     ]
    }
   ],
   "source": [
    "merger = MergeResults(data_list, result_list, result_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21937"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.unsortedidx_sortedidx[22967]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.array(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([22967]),)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(temp == '00044944')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merger = MergeResults(data_list, result_list, result_dir)\n",
    "merger.merge_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_list\n",
    "del result_list\n",
    "del start_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = sp.coo_matrix((merger.data, (merger.ii, merger.jj)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del merger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = distance_matrix.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.save_npz(result_matrix_path, distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "build_central"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
